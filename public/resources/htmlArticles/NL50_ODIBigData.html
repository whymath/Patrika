<tr style='height:48.6pt'><td width=1293 valign=top style='width:970.05pt;border:solid #17365D 4.5pt;border-top:none;padding:0in 5.4pt 0in 5.4pt;height:48.6pt'><h3>Stepping into the Big Data world with ODI: Part II<o:p></o:p></h3><h2>Bhabani Mahapatra<span style='font-size:13.0pt'><o:p></o:p></span></h2><p class=MsoNormal><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>Welcome to the second edition of the Big Data and ODI series! This part focuses on Hive and the new ODI KM that supports Big Data Integration. In the first part we saw the basics of Hadoop Ecosystem and Hadoop Architecture. We also got to know about most of the Ecosystem components &#8211; NoSQL databases, and how Mappers and Reducers are used to process huge amount of data with the help of key-value pairs. If you have not gone through the first part of this series then I encourage you to go back and check for &#8220;OBP Newsletter &#8211; Issue 48&#8221;. Aspects covered in this part will include HIVE and the different versions of ODI that supports the new features. <o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><o:p>&nbsp;</o:p></span></p><h4>HIVE<o:p></o:p></h4><p class=MsoNormal><span style='font-family:"Cambria",serif'>Before stepping into ODI, let&#8217;s refresh our memory with some HIVE queries. HIVE is a great tool for querying large datasets without knowing much about underpinning of Hadoop. Here is the script for creating a table in Hive.<o:p></o:p></span></p><p class=MsoNormal><span style='color:#1F497D'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>CREATE TABLE IF NOT EXISTS employee (<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>e_mpid int,<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>ename String,<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>esalary String,<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>edesignation String<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>)<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>COMMENT &#8216;Employee information<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>ROW FORMAT DELIMITED<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>FIELDS TERMINATED BY &#8216;\t&#8217;<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>LINES TERMINATED BY &#8216;\n&#8217;<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>STORED AS TEXTFILE;<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>Now we will insert the data present in employee.txt file to this table. The insert query will look like this.<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>LOAD DATA LOCAL INPATH '/home/oracle/employee.txt' into table employee<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>I am sure you must be wondering about the contents of the file (for those with a good memory, in the previous article I had mentioned how logs from sensors, satellite, social media, etc. are stored in such files). The data in the file is given below:<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><b><span style='font-family:"Cambria",serif;color:#00B050'>ID&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SALARY&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; DESIGNATION<o:p></o:p></span></b></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>422&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ALEX&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4500&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; DEVELOPER<o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif;color:#00B050'>424&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; JENNY&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MANAGER<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>Oh but this looks like structured data! What about unstructured data like say, a Host server log file? Don&#8217;t worry, I am not going back on my word. J In that case two things should be kept in mind &#8211; how to load this log file, and what content are we actually interested in. Let me walk you through a small example. Here is some unstructured data from a log file:<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><div align=center><table class=MsoNormalTable border=0 cellspacing=0 cellpadding=0 style='border-collapse:collapse'><tr style='height:208.55pt'><td width=704 valign=top style='width:528.35pt;border:solid windowtext 1.0pt;padding:0in 5.4pt 0in 5.4pt;height:208.55pt'><p class=MsoNoSpacing><span style='font-family:"Cambria",serif;color:#00B050'>10.236.133.247 - - [Mon, 19 May 2014 16:31:33 GMT] &quot;GET /api/admin/job/aggregator/status HTTP/1.1&quot; 200 1847<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif;color:#00B050'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><b><span style='font-family:"Cambria",serif;color:#00B050'>&quot;<a href="https://blog.dwteam.in/admin"><span style='color:#00B050;text-decoration:none'>https://blog.dwteam.in/admin</span></a>&quot;</span></b><span style='font-family:"Cambria",serif;color:#00B050'> &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.137 Safari/537.36&quot;<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif;color:#00B050'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif;color:#00B050'>10.110.110.245 - - [Mon, 19 May 2014 17:39:43 GMT] &quot;GET /api/admin/job/aggregator/status HTTP/1.1&quot; 200 1984 <o:p></o:p></span></p><p class=MsoNoSpacing><b><span style='font-family:"Cambria",serif;color:#00B050'><o:p>&nbsp;</o:p></span></b></p><p class=MsoNoSpacing><b><span style='font-family:"Cambria",serif;color:#00B050'>&quot;<a href="https://blog.dwteam.in/admin"><span style='color:#00B050;text-decoration:none'>https://blog.dwteam.in/admin</span></a>&quot;</span></b><span style='font-family:"Cambria",serif;color:#00B050'> &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.137 Safari/537.36&quot;<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif;color:#00B050'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif;color:#00B050'>10.110.141.202 - - [Mon, 19 May 2014 18:37:02 GMT] &quot;GET /api/admin/job/aggregator/status HTTP/1.1&quot; 200 1984<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif;color:#00B050'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><b><span style='font-family:"Cambria",serif;color:#00B050'>&quot;<a href="https://blog.dwteam.in/admin"><span style='color:#00B050;text-decoration:none'>https://blog.dwteam.in/admin</span></a>&quot;</span></b><span style='font-family:"Cambria",serif;color:#00B050'> &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.137 Safari/537.36&quot;<o:p></o:p></span></p></td></tr></table></div><p class=MsoNormal><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>To process this we will create a table with single attribute of string data type and load the data using same command above. Next we will create another table with the structure we are looking for. And finally, write a query to parse the string and split them in to number of columns like below. <o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><div align=center><table class=MsoNormalTable border=0 cellspacing=0 cellpadding=0 style='border-collapse:collapse'><tr style='height:16.45pt'><td width=173 valign=top style='width:130.1pt;border:solid windowtext 1.0pt;padding:0in 5.4pt 0in 5.4pt;height:16.45pt'><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>LOG_DATE<o:p></o:p></span></p></td><td width=159 valign=top style='width:119.2pt;border:solid windowtext 1.0pt;border-left:none;padding:0in 5.4pt 0in 5.4pt;height:16.45pt'><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>IP_ADDRESS<o:p></o:p></span></p></td><td width=205 valign=top style='width:153.95pt;border:solid windowtext 1.0pt;border-left:none;padding:0in 5.4pt 0in 5.4pt;height:16.45pt'><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>PROTOCOL<o:p></o:p></span></p></td><td width=167 valign=top style='width:125.15pt;border:solid windowtext 1.0pt;border-left:none;padding:0in 5.4pt 0in 5.4pt;height:16.45pt'><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>URL<o:p></o:p></span></p></td></tr></table></div><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>Below is the query for creating those tables. Please notice that I have used an EXTERNAL keyword in the create table script as because if you drop the table at some point, you can still have the data in HDFS. Without EXTERNAL if you drop the table then you lose the file in HDFS as well. The LOCAL keyword in the load command points to the local system. If you want to load all the files in a specific directory then don&#8217;t give any file name while loading data.<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing align=center style='text-align:center'><span style='font-family:"Cambria",serif'><img border=0 width=628 height=384 style='width:6.5416in;height:4.0in' id="_x0000_i1048" src="imap-message://yohan%2Emathew%40oracle%2Ecom@stbeehive.oracle.com/Sent%20Items#8834?header=saveas&part=1.1.2.32&filename=image071.jpg" alt=odi1.jpg><o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>Now if you will query the table you will get below mentioned result-set. This query is actually creating Mappers and Reducers for you automatically. Isn&#8217;t that great! <o:p></o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing align=center style='text-align:center'><span style='font-family:"Cambria",serif'><img border=0 width=548 height=338 style='width:5.7083in;height:3.5208in' id="_x0000_i1049" src="imap-message://yohan%2Emathew%40oracle%2Ecom@stbeehive.oracle.com/Sent%20Items#8834?header=saveas&part=1.1.2.33&filename=image072.jpg" alt=odi2.jpg><o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNormal><span style='font-family:"Cambria",serif'>If you want to know more about hive queries, UDFs, partitions, etc., then you can look up Google for the same. I hope the above refresher section to HIVE would have helped all of you remember the basics. Now, let us proceed to ODI.<o:p></o:p></span></p><p class=MsoNormal><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><h4>Oracle Data Integrator (ODI)<span style='font-size:11.0pt'><o:p></o:p></span></h4><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>Since Oracle's vision is to provide a comprehensive solution to address the Big Data challenges, Oracle is providing Big Data connectors to facilitate data access between Hadoop and Oracle Database shown below. As our objective is to integrate data using ODI, we will only concentrate on the ODI application adapter for Hadoop.<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>Oracle Data Integrator Application Adapter for Hadoop (ODI AAH)<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>Oracle SQL Connector for HDFS (Oracle Direct Connector for HDFS)<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>Oracle Loader for Hadoop (OLH)<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>Oracle R Connector for Hadoop<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.25in'><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing align=center style='margin-left:.25in;text-align:center'><span style='font-family:"Cambria",serif'><img border=0 width=470 height=246 style='width:4.8958in;height:2.5625in' id="_x0000_i1050" src="imap-message://yohan%2Emathew%40oracle%2Ecom@stbeehive.oracle.com/Sent%20Items#8834?header=saveas&part=1.1.2.34&filename=image073.jpg" alt=odi3.jpg><o:p></o:p></span></p><p class=MsoNormal align=center style='text-align:center'><i><span style='font-family:"Cambria",serif'>Above diagram describes how ODI AAH interacts with HDFS via hive. ODI generates hive code which are sent to hive server and gets converted into map reduce jobs.<o:p></o:p></span></i></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>ODI 12.1.3 and 12.1.3.1 has extended the Hadoop capabilities with number of exciting features, such as:<o:p></o:p></span></p><ol style='margin-top:0in' start=1 type=1><li class=MsoNoSpacing style='mso-list:l9 level1 lfo12'><span style='font-family:"Cambria",serif'>Loading of RDBMS data from and to Hadoop using Sqoop<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l9 level1 lfo12'><span style='font-family:"Cambria",serif'>Support for Apache HBase databases<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l9 level1 lfo12'><span style='font-family:"Cambria",serif'>Support for Hive append functionality (in earlier version append was not supported)<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l9 level1 lfo12'><span style='font-family:"Cambria",serif'>Orchestration of ODI Jobs using Oozie<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l9 level1 lfo12'><span style='font-family:"Cambria",serif'>Retrieval of Hadoop Audit Logs<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l9 level1 lfo12'><span style='font-family:"Cambria",serif'>HDFS access in Oracle Data Integrator File Tools<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l9 level1 lfo12'><span style='font-family:"Cambria",serif'>New Flatten and Jagged Components<o:p></o:p></span></li></ol><p class=MsoNoSpacing><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing style='text-align:justify'><span style='font-family:"Cambria",serif'>Wow, that&#8217;s lot of features! If you are really an ETL geek you will definitely feel restless to give them a try. But remember one thing &#8211; &#8220;Behind every interface in ODI there is a KM&#8221;. J If you are familiar with ODI, you would definitely accept that the <b>Knowledge Module</b>, or KM, is the heart of ODI integration. There are a set of KMs available which are grouped together and added to the adapters we talked before. Then ODI will use these KMs to implement MapReduce jobs with the help of HIVE and HIVEQL (Hive Query Language). Remember, since ODI uses JDBC drivers to connect to most of the technology, you have to create a few environment variables ($HIVE_HOME, $HADOOP_HOME, $OSCH_HOME) to point to the libraries followed by an entry in additional_path.txt present in userlib directory. <o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>Below is the list of Knowledge Modules supported by ODI. We will discuss these in the next article.<o:p></o:p></span></p><p class=MsoNoSpacing><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><div align=center><table class=MsoNormalTable border=0 cellspacing=0 cellpadding=0 width=722 style='width:541.8pt;border-collapse:collapse'><tr style='height:76.7pt'><td width=405 style='width:303.4pt;border:solid windowtext 1.0pt;padding:0in 5.4pt 0in 5.4pt;height:76.7pt'><ol style='margin-top:0in' start=1 type=1><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>LKM File to Oracle OLH-OSCH, <o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>LKM Hive to Oracle OLH-OSCH Direct<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>LKM Hive to SQL SQOOP<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>LKM Hive to Oracle (Big Data SQL)<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>LKM File to Hive LOAD DATA Direct<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>IKM File to Hive (Load Data)<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>IKM Hive Control Append<o:p></o:p></span></li><li class=MsoNoSpacing style='mso-list:l10 level1 lfo14'><span style='font-family:"Cambria",serif'>IKM Hive to HBase Incremental Update (HBase-SerDe)</span><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p></o:p></span></li></ol></td><td width=318 style='width:238.4pt;border:solid windowtext 1.0pt;border-left:none;padding:0in 5.4pt 0in 5.4pt;height:76.7pt'><p class=MsoNoSpacing style='margin-left:.25in'><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>1. IKM Hive Transform<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>2. IKM File-Hive to Oracle (OLH)<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>3. IKM File-Hive to SQL (SQOOP)<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>4. IKM Hive to HBase Incremental Update (HBase-SerDe)<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>5. IKM SQL to Hive-HBase-File (SQOOP)<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>6. CKM Hive<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>7. RKM Hive<o:p></o:p></span></p><p class=MsoNoSpacing style='margin-left:.5in'><span style='font-family:"Cambria",serif'>8. RKM Hbase</span><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p></o:p></span></p></td></tr></table></div><p class=MsoNoSpacing><span style='font-size:10.0pt;font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></p><p class=MsoNoSpacing><span style='font-family:"Cambria",serif'>Is it overwhelming? Don&#8217;t worry we will take a break in this journey and meditate on what we have learnt so far. Did you also notice that we have already stepped into the Big Data world? Remember that list of jargon I had mentioned in my first article? So far, we have covered Hadoop, HDFS, and HIVE. In the upcoming edition, we will learn about SQOOP, HBASE and its implementation in ODI. Since this technology is going to play a vital role in the coming years, start learning about them now before it gets too late. Until next time!<o:p></o:p></span></p><p class=MsoNoSpacing><sup><span style='font-family:"Cambria",serif'><o:p>&nbsp;</o:p></span></sup></p></td></tr>